References
	Mapping IDL to Python
		http://www.scicoder.org/mapping-idl-to-python/
		: Not always the best reference. For example, for Amoeba minimisation
		: it points to a bespoke python script rather than the Scipy
		: implementation

Initial questions
	Data
		input formats?
			ESRI
			ENVI HDR
			Other raster formats (GeoTIFF etc)
			Custom
				binary?
					watch for endianess
		output formats?
		What data structures are used?
			What is the best way to translate them to numpy?
		Does the code need to explicitly deal with spatial aspects of the data (projections etc)?
			or does it just see an array of pixels
		How can I breakdown the large global data structure to be more modular?
			Identify coherent subsets of data required by the processing modules
	What are the plotting requirements?
		Should the plots be generated by Python at all?
			: Can I just write out to HDF using an appropriate convention(CF-1.2?),
			: and then use standard tools (ESRI, ENVI, Panoply) to visualise the
			: data?
		If plotting from Python, what library will I need?
			Matplotlib, Basemap, veusz...
	Processing:
		numpy, scipy
		does single or double precision matter?
	What IDL-specific capabilities are used that might be hard to substitute in Python?

sambuca_2009.pro
	function machine_name
		:Straightforward. On windows it searches the environment and returns 
		:the machine name. On linux it returns "unix" but it could easily
		:check the value of $HOSTNAME.
	function DO_whole_guacamole
		: Contrary to the name, it doesn't "do" or execute anything. It just
		: appears to construct the whole_guacamole structure
		variables
			pstate
			zzzz
		Where is the common SAMBUCA_share structure defined?
			:It looks like it is setup in sambuca_2009_wid.pro, function SAMBUCA_2009_pre
		whole_guacamole is a structure of arrays
			What is the purpose of each array?
				name
				value
				pupper
					:an upper limit to something
				plower
					:a lower limit to something
				start
				scale
					:defines the initial step size used by the amoeba
					:minimisation routine.
			Number of parameters is hard-coded. 
				Could be data driven?
			Ask the team for explanation of each element set
				what is 'CHL', 'CDOM' etc
	procedure restore_envi_library
		Function
			Searches for an ENVI file by name,
			Reads metadata for the file
			Puts the metadata into a structure used by Sambuca
		The Python GDAL library reads ENVI rasters. Will it also let me query the metadata?
	function SAMBUCA_SA_V12_fwdVB
		: From the name, I think it represents version 12 of the forward model
		||variables|description|vector/scalar/structure|
		|ZZ|looks like a big collection of inputs|vector?|
		|input_params.theta_air||scalar|
		|input_params.lambda0cdom||scalar|
		|input_spectra.wl||vector|
		|input_spectra.awater|||
		|input_spectra.bbwater|||
		|input_spectra.acdom_star|abs. coeff for CDOM, where a_cdom_550 = 1||
		|input_spectra.atr_star|abs coeff og tripton, where a_tr_550 = sample dependent||
		|input_spectra.bbph_star|backscatter due to phytoplankton||
		|input_spectra.bbtr_star|backscatter due to tripton||
		|input_spectra.substrateR|||
		|thetaw|subsurface solar zenith angle in radians||
		|thetao|subsurface viewing angle in radians||
		|a_cdom_lambda0cdom||scalar|
		|n_wls|number of elements in wav (input_spectra.wl)||
		|CHL|chlorophyl concentration||
		|CDOM|cdom concentration||
		|TR|tripton concentration||
		|X_ph_lambda0x|specific backscatter of chlorophyl at lambda0x||
		|X_tr_lambda0x|specific backscatter of tripton at lambda0x||
		|Sc|cdom absorption slope||
		|Str|TR absorption slope||
		|a_tr_lambda0tr|||
		|Y|||
		|q1|||
		|q2|||
		|q3|||
		|H|||
		|Qwater|||
		|a|||
		|bb|||
		|u|||
		|kappa|||
		|DuColumn|opt. path elongation for scatterd photons from column||
		|DuBottom|opt. path elongation for scatterd photons from bottom||
		|rrsdp|remote sensing reflectance for opt[optional? optically?] deep water||
		|Kd|||
		|Kuc|||
		|Kub|||
		|rrs|||
		|closed_spectrum|||
		|closed_deep_spectrum|||

amoeba_clw7.pro
	Is the 7 a version number?
		If so, what is the history?
	Performs multidimensional minimisation of a function using the downhill simplex method
		Does not require a derivative function
	Appears to be a modified version of the IDL standard function.
		: I suspect that one modification is the splitting out of the
		: amotry_CLW2 function, and the addition of the common block, as the
		: original function block comment indicates no common blocks. Would
		: need to diff against original to check, but it probably doesn't
		: matter for the port.
		ToDo: identify whether a replacement exists in SciPy.
			Yes
				: downhill simplex (Nelder-Mead/Amoeba) is available as an option
				: in minimise using method='Nelder-Mead'
				: http://stackoverflow.com/questions/9613381/python-function-minimisation-without-derivative
				: http://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html?highlight=nelder
			Does the IDL function do anything strange that will prevent use of the SciPy version?

IDL quirks to watch
	arrays
		IDL arrays are row-major, but differ from standard matrix notation by using (column, row) rather than (row, column)
		: so indexing looks like column-major but it's not. Rationale is that
		: memory layout for 2D images matches the data access ordering of device
		: scanlines
			will just have to watch indexing orders in Python
		array subscripts are 0-based (yeay)
		implicit array operations
		default is to use [] for array subscripts, but () is legal (and confusing since it looks like a function call)
	Common Blocks
		Global data dressed up so it doesn't look like a bad idea, but it is.
		it could be addressed by objects: common blocks become object data, functions and procedures become methods
	Functions & Procedures
		It looks like procedures don't have a return value, but functions do.
		Side effects!! Both functions and procedures routinely make permanent changes to input arguments
		Keyword arguments
			names can be shortened, so watch for errors caused by similar names
	dynamic typing
		values have a hard type (string, float, double etc)
		references can point to any type
		: So a='a' followed by a=3 does not change a string to an int. It just
		: changes the data type referenced by a
	data types
		default int is only 16 bits. Need long for 32 bits
		float (32 bits) and double (64 bits) make sense

Sambuca common features
	tight binding to GUI
		:a number of Sambuca functions directly trigger an IDL message box. In
		:python it will be better to throw an exception. This will keep
		:a clean separation between the core code and any GUI that may or may
		:not be layered over the top.
